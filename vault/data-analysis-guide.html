<!doctype html>



  


<html class="theme-next mist use-motion">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.lug.ustc.edu.cn/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content=",," />





  <link rel="alternate" href="/atom.xml" title="小土刀" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.1" />






<meta name="description" content="本文是我学习数据分析时候的一些笔记和总结，因为时间比较长了，参考链接都遗失了，在这里感谢各位老司机在我学习过程中给我的帮助。">
<meta name="keywords">
<meta property="og:type" content="website">
<meta property="og:title" content="数据分析指南">
<meta property="og:url" content="http://wdxtub.com/vault/data-analysis-guide.html">
<meta property="og:site_name" content="小土刀">
<meta property="og:description" content="本文是我学习数据分析时候的一些笔记和总结，因为时间比较长了，参考链接都遗失了，在这里感谢各位老司机在我学习过程中给我的帮助。">
<meta property="og:updated_time" content="2016-09-10T02:39:03.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="数据分析指南">
<meta name="twitter:description" content="本文是我学习数据分析时候的一些笔记和总结，因为时间比较长了，参考链接都遗失了，在这里感谢各位老司机在我学习过程中给我的帮助。">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 4016951,
      author: '博主'
    }
  };
</script>

  <title>
  

  
    数据分析指南 | 小土刀
  
</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  





  <!-- hexo-inject:begin --><!-- hexo-inject:end --><script type="text/javascript">
    (function() {
      var hm = document.createElement("script");
      hm.src = "//tajs.qq.com/stats?sId=59042340";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




  <div style="display: none;">
    <script src="http://s6.cnzz.com/stat.php?id=1260625611&web_id=1260625611" type="text/javascript"></script>
  </div>





  
  
    
  

  <div class="container one-collumn sidebar-position-left  ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">小土刀</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle">Agony is my triumph</p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-work">
          <a href="/2016/09/11/work-page" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-pencil"></i> <br />
            
            作品
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tech">
          <a href="/2009/09/11/tech-page" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-battery-full"></i> <br />
            
            技术
          </a>
        </li>
      
        
        <li class="menu-item menu-item-life">
          <a href="/1990/09/11/life-page" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-bolt"></i> <br />
            
            生活
          </a>
        </li>
      
        
        <li class="menu-item menu-item-booklist">
          <a href="/1997/09/11/booklist-page" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-diamond"></i> <br />
            
            书单
          </a>
        </li>
      
        
        <li class="menu-item menu-item-thanks">
          <a href="/thanks" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-gift"></i> <br />
            
            关于我
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="#" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup">
 <span class="search-icon fa fa-search"></span>
 <input type="text" id="local-search-input">
 <div id="local-search-result"></div>
 <span class="popup-btn-close">close</span>
</div>


    </div>
  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    
    
      <p>本文是我学习数据分析时候的一些笔记和总结，因为时间比较长了，参考链接都遗失了，在这里感谢各位老司机在我学习过程中给我的帮助。</p>
<a id="more"></a>
<hr>
<p>数据分析是我这一年多来才开始研究的方向，资历尚浅，但是看了不少科普类书籍，有一些小小的感悟，记录在这里。最后是之前上的一套公开课的笔记，感觉对于入门还是很有帮助的。</p>
<h2 id="统计分析中的一些陷阱"><a href="#统计分析中的一些陷阱" class="headerlink" title="统计分析中的一些陷阱"></a>统计分析中的一些陷阱</h2><ul>
<li>有 3 种谎言：谎言，糟糕透顶的谎言和统计资料</li>
<li>对于追求效率的公民而言，统计思维总有一天会和读写能力一样重要</li>
<li>使我们陷入麻烦的通常并非我们不知道的事情，而是那些我们知道却不正确的事情</li>
<li>整数总是不完善的</li>
<li>我需要完成一个很大的课题——统计学，但却感到我的写作功底十分有限，如果不牺牲准确性和完整性，就很难使人理解</li>
<li>单凭某一数据很难反应实情</li>
<li>一条河永远不可能高于它的源头，同理，对样本研究后得到的结论不会好于样本本身</li>
<li>一个以抽样为基础的报告如果要有价值，就必须使用具有代表性的样本，这种样本排除了各种误差</li>
<li>无形的误差与有形的误差一样容易破坏样本的可信度</li>
<li>普查工作者一般都具有足够的统计知识、技术以及调查费用以确保抽样的精确度。他们并非居心叵测之徒。但并不是所有能见到的数据都产生于这样良好的环境，也并不是所有的数据都会有附有类似的精确度说明</li>
<li>如果某条信息提供了显著性程度，你将对它有更深的了解。显著成都通常用概率表示。</li>
<li>将『正常的』与『期望的』混为一谈导致事情变得更糟</li>
<li>这些没有透露的数据其欺骗性在于人们经常忽略了它们的不存在，这当然也是使用这些数据的人获取成功的奥秘</li>
<li>当一个平均数、一张图表或者某种趋势遗漏了这些重要的数据，请对它们保留一些怀疑。</li>
<li>你的样本以多大的精度代表总体是可以用数据来衡量的，那就是：可能误差和标准误差</li>
<li>只有当差别有意义时才能称之为差别</li>
<li>注意比例尺和起始标尺，这可能会产生极大的误导性</li>
<li>利用一维图形的信息不对称，可以营造出非常夸张的视觉效果</li>
<li>如果你想证明某事，却发现没有能力办到，那么试着解释其他事情并假装它们是同一回事。</li>
<li>相关并不等于因果，一定要注意这里的区别</li>
<li>扭曲统计数据的最巧妙方法是利用地图</li>
<li>百分数也给误解提供了肥沃的土壤。和小数一样，它也能为不确切的食物蒙上精确的面纱</li>
<li>将一些看似能直接相加却不能这样操作的事情加在一起会产生大量的欺骗和隐瞒</li>
<li>对统计资料提出的五个问题<ol>
<li>谁说的？有意识的偏差和无意识的偏差</li>
<li>他是如何知道的？注意样本的有偏，数值是否足够大</li>
<li>遗漏了什么？</li>
<li>是否有人偷换了概念？</li>
<li>这个资料有意义吗？</li>
</ol>
</li>
<li>我们以为自己可以控制很多风险，但结果并非如此，也许这才是更大的威胁。</li>
<li>贪婪和恐惧是两个非常不稳定的因素，只有两者保持平衡，经济才能顺利发展。若贪婪在经济体系中占上风，就会产生经济泡沫；若恐惧因素压过贪婪，经济又会陷入恐慌。</li>
<li>狐狸型预测方法<ul>
<li>用概率的方法思考问题</li>
<li>今天的预测是你以后人生的第一个预测</li>
<li>寻求共识 </li>
</ul>
</li>
<li>信息是决定预测成败的关键，并不是信息越多，预测就越成功</li>
<li>经济是一个动态系统，不是一个方程式</li>
<li>运气和技能通常被视为两个极端，但两者之间的关系其实更复杂一些</li>
<li>若想做出更准确的预测，就必须承认我们的判断是不可靠的</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:center">狐狸型专家的想法</th>
<th style="text-align:center">刺猬型专家的想法</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">千伎百俩：汇聚不同学科的思想，忽略最初的政治派别</td>
<td style="text-align:center">一技之长：把大部分精力投入到一两个重大问题上，以怀疑的眼光看待『局外人』的观点</td>
</tr>
<tr>
<td style="text-align:center">适应力强：最初的方法失效后，试图找到新的方法，或同时寻求多种方法</td>
<td style="text-align:center">坚持力强：坚持『总揽一切』的方法，新数据只能用来改善原始模式</td>
</tr>
<tr>
<td style="text-align:center">严于律己：有时会愿意（或是欣于）承认预测中的错误并接受谴责</td>
<td style="text-align:center">固执己见：错误归咎到坏运气或特殊情况上——好模式没有赶上好时机</td>
</tr>
<tr>
<td style="text-align:center">承认复杂性：承认宇宙的复杂性，认为许多基本问题不可解决或本身就是不可预测的</td>
<td style="text-align:center">寻找秩序：一旦从噪声中找到信号，便期望世界遵循某种相对简单的支配关系</td>
</tr>
<tr>
<td style="text-align:center">谨慎：用概率术语表达预测结论，并且证明自己的观点是正确的</td>
<td style="text-align:center">自信：很少对自己的预测进行正面回复，并且不愿改变自己的预测</td>
</tr>
<tr>
<td style="text-align:center">经验主义：更多地依赖观察而非理论</td>
<td style="text-align:center">意识形态：期待日常的问题正是宏伟理论或斗争的体现</td>
</tr>
<tr>
<td style="text-align:center">较好的预测家</td>
<td style="text-align:center">较差的预测家</td>
</tr>
</tbody>
</table>
<h2 id="互联网数据挖掘"><a href="#互联网数据挖掘" class="headerlink" title="互联网数据挖掘"></a>互联网数据挖掘</h2><p>万小军 <a href="http://www.icst.pku.edu.cn/lcwm" target="_blank" rel="external">http://www.icst.pku.edu.cn/lcwm</a></p>
<h2 id="互联网挖掘概述"><a href="#互联网挖掘概述" class="headerlink" title="互联网挖掘概述"></a>互联网挖掘概述</h2><ul>
<li>Web 挖掘<ul>
<li>由 Etzioni(1996) 提出</li>
<li>使用数据挖掘的技术自动从 Web文档/服务发现和提取信息和知识，包括隐含的模式和关系等</li>
</ul>
</li>
<li>相关技术<ul>
<li>信息检索</li>
<li>互联网</li>
<li>数据库</li>
<li>机器学习</li>
<li>自然语言处理</li>
<li>数据挖掘</li>
</ul>
</li>
<li>相关学术会议<ul>
<li>Web 搜索: SIGIR, WWW, CIKM, WSDM</li>
<li>数据挖掘: KDD, ICDM</li>
<li>自然语言处理: ACL, EMNLP</li>
<li>多媒体检索: ACM, MM</li>
</ul>
</li>
<li>应用<ul>
<li>垂直搜索</li>
<li>个性化推荐</li>
<li>智能问答</li>
<li>机器翻译</li>
<li>舆情监测</li>
<li>情报与反恐</li>
<li>预测</li>
</ul>
</li>
</ul>
<h2 id="文本信息检索"><a href="#文本信息检索" class="headerlink" title="文本信息检索"></a>文本信息检索</h2><ul>
<li>两个核心问题<ul>
<li>效果<ul>
<li>如何准确匹配查询与文档</li>
<li>基于检索模型</li>
</ul>
</li>
<li>效率<ul>
<li>如何快速返回检索结果</li>
<li>基于索引</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="文档表示"><a href="#文档表示" class="headerlink" title="文档表示"></a>文档表示</h3><ul>
<li>元描述(Meta-descriptions)<ul>
<li>域信息(author, title, date)</li>
<li>关键词、受控词汇</li>
<li>分类</li>
<li>优点<ul>
<li>主要依赖人工标注，结果比较可靠</li>
<li>基于受控词汇的检索很高效</li>
</ul>
</li>
<li>不足<ul>
<li>人工标注非常耗时</li>
<li>检索受限制</li>
</ul>
</li>
</ul>
</li>
<li>自动文档表示<ul>
<li>词袋(Bag of Words)<ul>
<li>一篇文档由该文档中出现的词的集合所表示</li>
<li>词语的无序集合，句法信息丢失</li>
<li>符号化(tokenization):识别词的边界</li>
<li>英文中大小写</li>
<li>词语形态规范化<ul>
<li>匹配 company 和 companies? sell 与 sold?</li>
<li>删除词语的形态信息: 时态，数量…</li>
</ul>
</li>
<li>词根(Stemming)<ul>
<li>删除后缀</li>
<li>基于规则进行(例如 Porter’s stemmer)</li>
<li>Stemming 的结果可能不是词语</li>
<li>不相关的词可能具有相同的 stem</li>
</ul>
</li>
<li>词形还原(Lemmatization)<ul>
<li>将词语变为其语法原型(syntactic stem)</li>
<li>使用一般规则与例外处理</li>
<li>处理结果仍然为词</li>
<li>处理过程要考虑词性的不同</li>
</ul>
</li>
<li>停用词(Stop Words)<ul>
<li>不具有内容信息的词</li>
<li>停用词表依赖于具体文档集及具体应用</li>
<li>过滤停用词的原因<ul>
<li>停用词并不能提高检索效果</li>
<li>可以大幅减少索引大小</li>
<li>减少检索时间</li>
</ul>
</li>
</ul>
</li>
<li>大部分互联网搜索引擎并不使用 stemming/lemmatizatoin<ul>
<li>文档集很大</li>
<li>不太考虑召回率</li>
<li>Stemming 结果并不完美</li>
</ul>
</li>
<li>大部分互联网搜索引擎使用停用词表</li>
<li>无法从词袋表示恢复原文档</li>
<li>优点: 简单、有效</li>
<li>缺点: 忽略了词之间和句法关系以及篇章结构的信息</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="文档索引"><a href="#文档索引" class="headerlink" title="文档索引"></a>文档索引</h3><ul>
<li>目的在于提高检索效率</li>
<li>索引对象的选择</li>
<li>Phrase 识别比较困难，并不能显著提高检索效果</li>
<li>通常采用 word 构建索引</li>
<li>索引压缩: 减小索引大小</li>
<li>动态索引: 索引库的动态维护、更新</li>
<li>分布式索引: 索引信息分布在不同机器上</li>
<li>具体细节参阅 Lucene 开源检索系统的相关代码</li>
</ul>
<h4 id="倒排索引-inverted-index"><a href="#倒排索引-inverted-index" class="headerlink" title="倒排索引(inverted index)"></a>倒排索引(inverted index)</h4><ul>
<li>以关键词为核心对文档进行索引</li>
<li>帮助快速地找到文档中所包含的关键词</li>
<li>可看做连标数组，每个链表的表头包含关键词，其后序单元则包括所有包括这个关键词的文档标号，以及一些其他信息，如该词的频率和位置等</li>
<li>优势<ul>
<li>关键词个数比文档少，因此检索效率高</li>
<li>特别适合信息检索</li>
</ul>
</li>
<li>数据结构<ul>
<li>关键词查询一般采用 B-Tree 或哈希表</li>
<li>文档列表组织一般采用二叉搜索树</li>
</ul>
</li>
</ul>
<h3 id="文本信息检索模型"><a href="#文本信息检索模型" class="headerlink" title="文本信息检索模型"></a>文本信息检索模型</h3><ul>
<li>基本思想: 如果一篇文档与一个查询相似，那么该文档与查询相关</li>
<li>相似性<ul>
<li>字符串匹配</li>
<li>相似的词汇</li>
<li>相同的语义</li>
</ul>
</li>
<li>检索模型<ul>
<li>对实际检索过程的抽象和建模</li>
<li>终极目标是基于语义进行匹配</li>
</ul>
</li>
</ul>
<h4 id="布尔模型-Boolean-Model"><a href="#布尔模型-Boolean-Model" class="headerlink" title="布尔模型(Boolean Model)"></a>布尔模型(Boolean Model)</h4><ul>
<li>基于布尔代数</li>
<li>优点<ul>
<li>简单</li>
<li>对查询严格掌控</li>
</ul>
</li>
<li>缺点<ul>
<li>一般用户难以构造布尔查询</li>
<li>检索结果文档无法排序</li>
<li>严格匹配，导致过少或过多的检索结果</li>
</ul>
</li>
<li>尽管布尔模型不再用作主流文档检索模型，但其思想常用于实现高级(综合)检索功能</li>
</ul>
<h4 id="向量空间模型-Vector-Space-Model"><a href="#向量空间模型-Vector-Space-Model" class="headerlink" title="向量空间模型(Vector Space Model)"></a>向量空间模型(Vector Space Model)</h4><ul>
<li>现代信息检索系统中比较常用的检索模型</li>
<li>特性<ul>
<li>用户输入自由文本作为查询</li>
<li>对文档进行排序</li>
<li>匹配准则放松</li>
</ul>
</li>
<li>思想: 文档与查询都是高维空间中的一个向量</li>
<li>向量空间表示<ul>
<li>文档是词语组成的向量</li>
<li>词语是文档组成的向量</li>
<li>查询是词语组成的向量</li>
</ul>
</li>
<li>相似性<ul>
<li>用内积衡量<ul>
<li>缺点<ul>
<li>长文档由于更可能包含匹配词语，因而更可能相关</li>
<li>然而，如果两篇文档具有同样的相似值，用户更倾向于短文档，短文档更聚焦在用户信息需求上</li>
</ul>
</li>
<li>相似性计算中应该考虑文档长度(进行规范化)</li>
</ul>
</li>
<li>用夹角来衡量<ul>
<li>向量归一化</li>
<li>余弦度量(Cosine Measure)</li>
<li>余弦相似度(Cosine Similarity)</li>
</ul>
</li>
</ul>
</li>
<li>词语权重<ul>
<li>之前采用二值表示: 非 1 即 0<ul>
<li>没有反映词语频率</li>
<li>假定所有词语均同等重要</li>
</ul>
</li>
<li>tf: 词语出现的频率<ul>
<li>tf~i,j~ = frequency of term i in document j</li>
</ul>
</li>
<li>idf: 区别不同词语的重要性</li>
<li>tfidf</li>
</ul>
</li>
<li>其他相似性度量<ul>
<li>Minkowski metric(dissimilarity)</li>
<li>Euclidian distance(dissimilarity)</li>
<li>Jacquard measure</li>
<li>Dice’s coefficient</li>
</ul>
</li>
</ul>
<h4 id="概率模型-Probabilistic-Model"><a href="#概率模型-Probabilistic-Model" class="headerlink" title="概率模型(Probabilistic Model)"></a>概率模型(Probabilistic Model)</h4><ul>
<li>1977 年由 Stephen Robertson 提出</li>
</ul>
<h3 id="信息检索评价"><a href="#信息检索评价" class="headerlink" title="信息检索评价"></a>信息检索评价</h3><ul>
<li>评鉴检索模型或搜索引擎的性能</li>
<li>搜索质量 vs 搜索效率</li>
<li>对搜索质量的评价<ul>
<li>评测数据集</li>
<li>评测指标</li>
</ul>
</li>
<li>相关评测<ul>
<li>TREC<ul>
<li>trec.nist.gov</li>
<li>最具影响力</li>
<li>多种信息检索任务，侧重于英文</li>
</ul>
</li>
<li>NTCIR<ul>
<li>research.nii.ac.jp/ntcir/</li>
</ul>
</li>
<li>CLEF<ul>
<li>www.clef-campaign.org</li>
</ul>
</li>
</ul>
</li>
<li>评测数据集<ul>
<li>一般人工构建</li>
<li>构成<ul>
<li>较大规模的文档集合 D</li>
<li>查询集 Q 以及每个查询 q 对应的相关文档列表 REL~q~</li>
</ul>
</li>
</ul>
</li>
<li>评价指标<ul>
<li>衡量检索结果与标准答案的一致性</li>
<li>对非排序检索的评价<ul>
<li>对检索结果集合进行整体评价</li>
<li>准确率(precision)与召回率(recall)，通常相互依赖</li>
<li>F 值(F-measure)</li>
</ul>
</li>
<li>对排序结果的评价<ul>
<li>考虑相关文档在检索结果中的排序位置</li>
<li>在不同 recall levels 的 precision 值</li>
<li>沿着检索结果列表从头往后考察</li>
</ul>
</li>
<li>对多级排序检索的评价<ul>
<li>NDCG - Normalized Discounted Cumulative Gain</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="Web-检索"><a href="#Web-检索" class="headerlink" title="Web 检索"></a>Web 检索</h2><p>Web 检索 = 文档检索 + 针对 Web 检索的新技术</p>
<h3 id="Web-页面采集"><a href="#Web-页面采集" class="headerlink" title="Web 页面采集"></a>Web 页面采集</h3><ul>
<li>Web Crawler, spider<ul>
<li>快速有效地收集尽可能多的有用 Web 页面，包括页面之间的链接结构</li>
</ul>
</li>
<li>Web 爬虫需要具备的特性<ul>
<li>健壮 robustness, 避免 spider traps</li>
<li>友好 politeness, 遵守 web server 的采集协议</li>
<li>分布式 distributed, 多台机器分布式采集</li>
<li>可扩展 scalable, 爬虫架构方便扩展</li>
<li>性能与效率，有效利用系统资源</li>
<li>质量 quality, 倾向于采集有用的页面</li>
<li>新颖 freshness, 获取网页的最新版本</li>
<li>可扩充 Extensible, 能够处理新数据类型、新的采集协议等</li>
</ul>
</li>
<li>Web 页面爬取策略<ul>
<li>深度优先</li>
<li>广度优先</li>
<li>实际应用中以广度优先为主，深度优先为辅</li>
</ul>
</li>
<li>难点<ul>
<li>暗网的采集，只有向数据库提交查询才形成的 Web 页面</li>
<li>Web 2.0 内容，脚本语言等生成的动态内容</li>
<li>多媒体内容</li>
</ul>
</li>
</ul>
<h3 id="Web-页面排序"><a href="#Web-页面排序" class="headerlink" title="Web 页面排序"></a>Web 页面排序</h3><ul>
<li>与查询相似度最大的网页并不一定是最好的结果</li>
<li>用户对 Web 页面的期望<ul>
<li>易于理解，可靠，作为查询话题的入口，能够回答差群的信息需求</li>
</ul>
</li>
<li>基于相关度的排序<ul>
<li>计算查询与页面内容的相似程度(依据文档检索模型)</li>
</ul>
</li>
<li>基于重要性的排序<ul>
<li>基于链接分析计算</li>
</ul>
</li>
<li>综合排序<ul>
<li>页面排序值 = 页面内容相关度 +/* 页面重要性</li>
</ul>
</li>
</ul>
<h3 id="Web-链接分析"><a href="#Web-链接分析" class="headerlink" title="Web 链接分析"></a>Web 链接分析</h3><ul>
<li>Web 页面之间的超链关系非常重要</li>
<li>一条从页面 A 指向页面 B 的链接表明<ul>
<li>A 与 B 相关</li>
<li>A 推荐/引用/投票/赞成 B</li>
</ul>
</li>
<li>经典算法<ul>
<li>HITS[Kleinberg, 1997] - Hypertext Induced Topic Selection</li>
<li>PageRank[Page &amp; Brin, 1998]</li>
</ul>
</li>
<li>排序沉入(Rank Sink)<ul>
<li>形成 loop, 没有 outlink</li>
<li>页面 A 与 B 相互提高 Rank, 而不向外分发 Rank</li>
</ul>
</li>
</ul>
<h3 id="基于学习的网页排序"><a href="#基于学习的网页排序" class="headerlink" title="基于学习的网页排序"></a>基于学习的网页排序</h3><ul>
<li>Learning to Rank 主流算法<ul>
<li>RankSVM</li>
<li>RankNet</li>
<li>ListNet</li>
</ul>
</li>
<li>Learning to Rank 工具包<ul>
<li>RankLib</li>
<li>people.cs.umass.edu/~vdang/ranklib.html</li>
</ul>
</li>
</ul>
<h3 id="搜索引擎优化-SEO"><a href="#搜索引擎优化-SEO" class="headerlink" title="搜索引擎优化(SEO)"></a>搜索引擎优化(SEO)</h3><ul>
<li>Search engine optimization<ul>
<li>提高网站或网页在搜索引擎中可见度(排名)的过程</li>
</ul>
</li>
<li>基本思想<ul>
<li>基于各类搜索引擎的工作原理(采集、索引、排序等)，对网站进行相关的优化的调整，提高网站在搜索引擎中的排名</li>
<li>白帽：合理优化，不牺牲用户体验</li>
<li>黑帽：不正当优化，牺牲用户体验<ul>
<li>重复、隐藏文字、链接工厂、桥页、跳页</li>
</ul>
</li>
</ul>
</li>
<li>影响排名的因素<ul>
<li>内部因素<ul>
<li>URL 中出现关键词</li>
<li>网页 Title 中出现关键词</li>
<li>常规内容中出现关键词</li>
<li>在页面的最后一段中出现关键词</li>
<li><code>&lt;Head&gt;</code> 标签 比如 h1, h2 中出现关键词</li>
<li>站内的链接中出现关键词</li>
<li>导向相关内容的导出链接</li>
<li>导出链接中出现关键词</li>
<li>图片文件名中出现关键词</li>
<li>Alt 标签中出现关键词</li>
<li>comment 中出现关键词</li>
<li>合理的频率更新内容</li>
<li>内容对搜索引擎的展示位置</li>
<li>网站结构循环 PR, 而非散发 PR</li>
<li>关键词进行适当的修饰(加粗、斜体等)</li>
</ul>
</li>
<li>外部因素<ul>
<li>大量的导入链接</li>
<li>从高 PR 值的网页获得导入链接</li>
<li>从相关内容网站获得导入链接</li>
<li>导入链接指向的网页有具体内容</li>
<li>锚文字中有关键词</li>
<li>锚文字周围有相关词</li>
<li>锚文字存在于文章或句子中</li>
<li>导入链接的时间长度，一般导入链接的存在时间有3-6个月</li>
<li>单向链接的价值高于交换链接</li>
<li>导入链接的页面的导出链接小于 100 个，流出链接越少越好</li>
<li>链接来自不同 IP</li>
<li>合理的导入链接增长频率</li>
</ul>
</li>
</ul>
</li>
<li>SEO 操作<ul>
<li>站外 SEO<ul>
<li>网站外部链接优化、网站的链接见识、网站的外部数据分析等</li>
<li>交换、购买链接，提交网址到分类目录等</li>
</ul>
</li>
<li>站内 SEO<ul>
<li>网站结构的设计、网站代码优化和内部链接优化、网站内容的优化、网站用户体验优化等</li>
<li>丰富网站关键词、主题集中、友好的网页结构、避免重复、有规律的更新等</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="自然语言处理基础"><a href="#自然语言处理基础" class="headerlink" title="自然语言处理基础"></a>自然语言处理基础</h2><p>又称<strong>自然语言理解</strong>，是人工智能和语言学领域的分支学科。利用计算机对人类特有的书面形式和口头形式的自然语言进行各种类型处理和加工的技术。</p>
<p>自然语言生成：利用计算机自动生成可理解的自然语言文本的技术</p>
<h3 id="基本任务"><a href="#基本任务" class="headerlink" title="基本任务"></a>基本任务</h3><ul>
<li>关键任务<ul>
<li>自动分词</li>
<li>命名实体识别</li>
<li>词性标注</li>
<li>句法分析</li>
<li>语义分析</li>
<li>篇章分析</li>
</ul>
</li>
<li>应用型任务<ul>
<li>机器翻译 Translation</li>
<li><strong>文本分类</strong> Classification</li>
<li>情感分析</li>
<li>信息检索与过滤 Mining/Retrieval</li>
<li>自动问答 Question Answering</li>
<li><strong>信息抽取</strong> Extraction</li>
<li><strong>自动文摘</strong> Summarization</li>
<li>人机对话 Dialogue</li>
</ul>
</li>
</ul>
<h3 id="为什么如此之难"><a href="#为什么如此之难" class="headerlink" title="为什么如此之难"></a>为什么如此之难</h3><ul>
<li>自然语言与生俱来的歧义问题</li>
<li>自然语言中存在未知的语言现象<ul>
<li>新的词汇</li>
<li>新的含义</li>
<li>新的用法和语句结构</li>
</ul>
</li>
<li>人类用语言进行社会交流时会省略公有制是，但机器很难获取及更新世界知识</li>
</ul>
<h3 id="推荐教材"><a href="#推荐教材" class="headerlink" title="推荐教材"></a>推荐教材</h3><ul>
<li>Foundations of Statistical Natrual Language Processing</li>
<li>Speech and Language Processing</li>
<li>统计自然语言处理</li>
</ul>
<h3 id="汉语自动分词"><a href="#汉语自动分词" class="headerlink" title="汉语自动分词"></a>汉语自动分词</h3><p>一般认为：词是最小的、能够独立运用的、有意义的语言单位</p>
<p><strong>汉语分词的挑战</strong></p>
<ul>
<li>词和词组的边界模糊</li>
<li>新词(未登陆词)</li>
<li>切分歧义<ul>
<li>汉字串 AJB 被称作<strong>交集型切分歧义</strong>，如果满足 AJ, JB 同时为词，此时汉字串 J 被称作交集串</li>
<li>汉字串 AB 被称作<strong>组合型切分歧义</strong>，如果满足条件 A, B, AB 同时为词</li>
<li>真歧义：存在两种或两种以上的真实存在的切分形式</li>
</ul>
</li>
</ul>
<p><strong>分词方法</strong></p>
<ul>
<li>简单的模式匹配<ul>
<li>正向最大匹配(FMM)、逆向最大匹配(BMM, 比正向更有效)、双向匹配(BM, 比较两种方法的结果，大颗粒词越多越好，非词典词和单子词越少越好，可以识别出交叉歧义)</li>
</ul>
</li>
<li>基于规则的方法<ul>
<li>最少分词算法</li>
</ul>
</li>
<li>基于统计的方法<ul>
<li>统计语言模型分词、串频统计和词形匹配相结合的汉语自动分词、无词典分词</li>
<li>第一步是候选网格构造：利用词典匹配，列举输入句子所有可能的切分词语，并以词网格形式保存</li>
<li>第二步计算词网格中的每一条路径的权值，权值通过计算图中的每一个节点(每一个词)的一元统计概率和节点之间的二元统计概率的相关信息</li>
<li>最后根据图搜索算法在图中找到一条权值最大的路径，作为最后的分词结果</li>
<li>优缺点：可利用不同的统计语言模型计算最优路径，具有比较高的分词正确率；但算法时间、空间复杂度较高</li>
</ul>
</li>
</ul>
<h3 id="词性标注-POS-Tagging"><a href="#词性标注-POS-Tagging" class="headerlink" title="词性标注(POS Tagging)"></a>词性标注(POS Tagging)</h3><ul>
<li>为句子中的每个词语标注词性(part-of-speech marker)</li>
<li>可看做是词法分析的关键任务，也可看做是句法分析的最低层次</li>
<li>对后续句法分析、词义消岐等任务非常有用</li>
</ul>
<h3 id="句法分析"><a href="#句法分析" class="headerlink" title="句法分析"></a>句法分析</h3><ul>
<li>句法/成分/短语结构分析 vs 依存关系分析</li>
<li>完全分析 vs 局部分析/浅层分析</li>
<li>Context Free Grammars(CFG)</li>
</ul>
<h2 id="数据挖掘概述与关联规则挖掘"><a href="#数据挖掘概述与关联规则挖掘" class="headerlink" title="数据挖掘概述与关联规则挖掘"></a>数据挖掘概述与关联规则挖掘</h2><p>数据挖掘从多学科领域发展而来：Statistics/AI, Machine Learning, Pattern Recognition, Database systems</p>
<h3 id="数据挖掘流程"><a href="#数据挖掘流程" class="headerlink" title="数据挖掘流程"></a>数据挖掘流程</h3><p><strong>Data</strong> -Selection-&gt; <strong>Target data</strong> -Preprocessing-&gt; <strong>Preprocessed data</strong> -Transformation-&gt; <strong>Transformed data</strong> -Data mining-&gt; <strong>Patterns</strong> -Interpretation/evaluatoin-&gt; <strong>Knowledge</strong></p>
<h3 id="数据挖掘任务"><a href="#数据挖掘任务" class="headerlink" title="数据挖掘任务"></a>数据挖掘任务</h3><ul>
<li>预测型(Prediction Methods): 基于一些变量预测其他变量的未知值或未来值<ul>
<li>分类 Classification</li>
<li>回归 Regression</li>
<li>偏差检测 Deviation Detection</li>
</ul>
</li>
<li>描述型(Description Methods): 发现描述数据的人们可解释的模式<ul>
<li>聚类 Clustering</li>
<li>关联规则挖掘 Association Rule Discovery</li>
<li>摘要 Summarization</li>
</ul>
</li>
</ul>
<h3 id="关联规则挖掘：定义"><a href="#关联规则挖掘：定义" class="headerlink" title="关联规则挖掘：定义"></a>关联规则挖掘：定义</h3><p>关联规则反映一个事物与其他事物之间的相互依存性和关联性。如果两个或者多个事物之间存在一定的关联关系，那么其中一个事物就能够通过其他事物预测到。关联规则表示了项之间的关系。</p>
<ul>
<li>给定一个记录集合，每个记录包含若干项<ul>
<li>产生依赖规则，可以基于某些项的出现预测一个项的出现</li>
</ul>
</li>
</ul>
<p>应用：市场营销</p>
<ul>
<li>假如发现一条规则</li>
<li>{面包圈..} -&gt; {薯片}</li>
<li>可以帮助提高薯片的销量</li>
</ul>
<h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>为数据集进行总结，提供一个简洁/紧凑的表示，包括可视化与报表生成</p>
<h3 id="回归"><a href="#回归" class="headerlink" title="回归"></a>回归</h3><ul>
<li>基于若干变量的值预测一个给定的具有连续值的变量的值<ul>
<li>假设一个线性或非线性的依赖模型</li>
</ul>
</li>
<li>举例<ul>
<li>基于广告开支预测新产品的销售额</li>
<li>基于温度、湿度、气压等预测风速</li>
<li>预测股票指数</li>
</ul>
</li>
</ul>
<p>为数据预测一个连续值，确定两种或两种以上变量间的相互依赖关系。</p>
<ul>
<li>最简单的情形: 一元线性回归<ul>
<li>只包括一个自变量 x 和一个因变量 y，且二者的关系可用一条直线近似表示</li>
<li>回归分析的目标为找一个线性函数迎合训练数据</li>
<li>可采用最小二乘法</li>
</ul>
</li>
<li>其他回归方法<ul>
<li>Logistic 回归</li>
<li>岭回归</li>
<li>支持向量回归</li>
</ul>
</li>
<li>回归结果评价<ul>
<li>均方误差(Mean Squared Error, MSE)</li>
<li>均方根误差(root mean square error, RMSE)</li>
</ul>
</li>
</ul>
<h3 id="偏差-异常检测"><a href="#偏差-异常检测" class="headerlink" title="偏差/异常检测"></a>偏差/异常检测</h3><ul>
<li>从正常行为中检测显著的偏差/异常</li>
<li>举例<ul>
<li>信用卡欺诈检测</li>
<li>网络入侵检测</li>
</ul>
</li>
</ul>
<h3 id="数据挖掘工具"><a href="#数据挖掘工具" class="headerlink" title="数据挖掘工具"></a>数据挖掘工具</h3><ul>
<li>Free open-source software and application<ul>
<li>Weka</li>
<li>GATE</li>
<li>Carrot2</li>
<li>NLTK</li>
<li>Orange</li>
<li>RapidMiner</li>
<li>KNIME</li>
</ul>
</li>
<li>Commercial software<ul>
<li>IBM InfoSphere Warehouse</li>
<li>Microsoft Analysis Services</li>
<li>SAS Enterprise Miner</li>
<li>STATISTICA Data Miner</li>
<li>Oracle Data Mining</li>
</ul>
</li>
</ul>
<h3 id="数据挖掘的挑战"><a href="#数据挖掘的挑战" class="headerlink" title="数据挖掘的挑战"></a>数据挖掘的挑战</h3><ul>
<li>可拓展性</li>
<li>挖掘高维数据、高速数据流</li>
<li>挖掘序列数据、时间序列数据</li>
<li>从复杂、异构、网络化数据中挖掘复杂知识</li>
<li>挖掘低质量数据</li>
<li>安全性、隐私保护</li>
</ul>
<h2 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h2><p>将数据划分到已知类别。分类器的构建基于有监督学习(标注数据:训练集)</p>
<ul>
<li>给定一个样例集合(训练集)<ul>
<li>每个样例包含一个属性集合，其中一个属性是类标记/类号</li>
</ul>
</li>
<li>基于训练集构建一个模型，该模型将类标记属性看作是其它属性值的一个函数</li>
<li>目标：对心的样例尽可能准确地赋予标记<ul>
<li>基于一个测试集来评估模型的准确性</li>
</ul>
</li>
</ul>
<p>Training Set -&gt; Learn Classifier -&gt; Model &lt;- Test set</p>
<ul>
<li>二类分类：正、负</li>
<li>多类分类：多类(&gt;=3)</li>
</ul>
<p>二类分类是分类问题的最基本形式，多类分类问题可通过转化为二类分类问题加以解决。</p>
<ul>
<li>One vs. One<ul>
<li>对于 K 类分类需要 K(K-1)/2 个二类分类器</li>
<li>测试分类时采用投票方式确定类别</li>
<li>E.g. Labels: a, b, c</li>
<li>分类器: a vs b, b vs c, a vs c</li>
</ul>
</li>
<li>One vs. All(Rest):<ul>
<li>对于 K 类分类需要 K 个二类分类器</li>
<li>测试分类时取返回最大值的类别</li>
<li>E.g. Labels: a, b, c</li>
<li>分类器: a vs (b, c), b vs (a, c), c vs (a, b)</li>
</ul>
</li>
</ul>
<p>层次式分类，类别构成层次式结构(树状)。中图法、ODP目录。</p>
<ul>
<li>应用<ul>
<li>新闻分类</li>
<li>广告页面判别</li>
<li>垃圾邮件过滤</li>
<li>垃圾短信过滤</li>
<li>博客风格判断</li>
<li>评论情感分析</li>
</ul>
</li>
</ul>
<h3 id="基于规则的分类"><a href="#基于规则的分类" class="headerlink" title="基于规则的分类"></a>基于规则的分类</h3><p>人工/专家制定分类规则，使用布尔操作符(AND, OR, NOT)，可将规则组织成决策树，节点代表规则，叶节点代表类别</p>
<ul>
<li>优势<ul>
<li>透明，易于理解，易于修改</li>
</ul>
</li>
<li>劣势<ul>
<li>复杂，耗时</li>
<li>主要依赖人工/专家的智能，而非系统/机器智能</li>
<li>不易拓展</li>
<li>绝对的类别划分，无置信度</li>
</ul>
</li>
</ul>
<h3 id="基于统计的分类"><a href="#基于统计的分类" class="headerlink" title="基于统计的分类"></a>基于统计的分类</h3><ul>
<li>优势<ul>
<li>可以输出置信概率、允许阈值控制、可扩展</li>
</ul>
</li>
<li>劣势<ul>
<li>需要已标注好的训练数据</li>
</ul>
</li>
<li>典型方法<ul>
<li>朴素贝叶斯</li>
<li>Rocchio</li>
<li>K 近邻</li>
<li>支持向量机</li>
</ul>
</li>
</ul>
<h3 id="文本统计分类流程"><a href="#文本统计分类流程" class="headerlink" title="文本统计分类流程"></a>文本统计分类流程</h3><ul>
<li>预处理<ul>
<li>Tokenization</li>
<li>Filtering</li>
<li>Stemming</li>
</ul>
</li>
<li>特征计算<ul>
<li>tf</li>
<li>Log(tf+1)</li>
<li>tfidf</li>
</ul>
</li>
<li>特征选择<ul>
<li>MI</li>
<li>Chi-Square</li>
<li>Information Gain</li>
</ul>
</li>
<li>分类学习<ul>
<li>SVM</li>
<li>Rocchio</li>
<li>Naive Bayes</li>
</ul>
</li>
<li>结果评估<ul>
<li>Recall</li>
<li>F-Measure</li>
<li>Precision</li>
</ul>
</li>
</ul>
<h3 id="文本分类-特征向量表示"><a href="#文本分类-特征向量表示" class="headerlink" title="文本分类-特征向量表示"></a>文本分类-特征向量表示</h3><ul>
<li>文本表示为特征向量<ul>
<li>词语(term): 基本单元</li>
<li>权重 TF * IDF<ul>
<li>TF: 词频</li>
<li>IDF: log(N/DF), N 为文档总数量，DF 为包含该词语的文档数量</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="文本分类-特征选择"><a href="#文本分类-特征选择" class="headerlink" title="文本分类-特征选择"></a>文本分类-特征选择</h3><ul>
<li>好处<ul>
<li>减少特征维数，改善效果</li>
<li>防止过拟合，增强模型的泛化能力</li>
<li>提高学习效率</li>
<li>提高模型的可解释性</li>
</ul>
</li>
<li>方法，从原有特征集合中找出一个更加有效的子集<ul>
<li>Document Frequency 文档频率<ul>
<li>词语的 DF 小于某个阈值去掉(太小，没有代表性)</li>
<li>词语的 DF 大于某个阈值也去掉(太多，没有区分度)</li>
</ul>
</li>
<li>Mutual Information 互信息<ul>
<li>MI 越大词语 t 和 c 共现程度越大</li>
</ul>
</li>
<li>Information Gain 信息增益<ul>
<li>词语 t 为整个分类所能提供的信息量(不考虑任何特征的熵和考虑该特征后的熵的差值)</li>
</ul>
</li>
<li>Information Ratio</li>
<li>Chi Squrae</li>
<li>Odd Ratio</li>
</ul>
</li>
</ul>
<h3 id="朴素贝叶斯分类"><a href="#朴素贝叶斯分类" class="headerlink" title="朴素贝叶斯分类"></a>朴素贝叶斯分类</h3><ul>
<li>基于概率理论的学习和分类方法</li>
<li>贝叶斯理论充当重要角色</li>
<li>分类是根据给定样本描述的可能的类别基础上产生的后验概率分布<ul>
<li>基于贝叶斯理论来计算后验概率</li>
</ul>
</li>
<li>分类原理：最大后验估计 MAP(maximum posteriori)</li>
</ul>
<h3 id="Rocchio-分类方法"><a href="#Rocchio-分类方法" class="headerlink" title="Rocchio 分类方法"></a>Rocchio 分类方法</h3><ul>
<li>使用中心向量(centroid vector)表示一个类别<ul>
<li>中心向量为某个类别下所有文档向量的平均向量</li>
<li>基于训练集计算</li>
</ul>
</li>
<li>对于新文档，计算该文档与每个类别的中心向量的距离/相似度<ul>
<li>基于余弦测度</li>
</ul>
</li>
<li>确定其类别为距离最小/相似性最大的类别</li>
<li>优势: 训练快速，模型很小，快速分类</li>
<li>劣势: 类别数量增加时准确率降低</li>
</ul>
<h3 id="K-近邻分类方法"><a href="#K-近邻分类方法" class="headerlink" title="K 近邻分类方法"></a>K 近邻分类方法</h3><ul>
<li>与 Rocchio 方法类似</li>
<li>检查新文档的 k 个近邻向量，利用这些近邻向量的类别来确定该文档的类别<ul>
<li>K 通过实验确定</li>
<li>“近邻” 通过相似度/距离测度来定义</li>
</ul>
</li>
<li>1 近邻分类方法<ul>
<li>将新文档划分到与其最相近的文档样例所属的类别</li>
</ul>
</li>
<li>K 近邻分类方法<ul>
<li>基于投票机制，将新文档划分到 k 个近邻文档中多数文档所属的类别</li>
<li>进一步，基于加权投票机制，根据近邻文档的相近程度，赋予每个近邻文档一定的权重</li>
</ul>
</li>
<li>优势<ul>
<li>不需要训练阶段</li>
<li>类别数量增加也具有良好的扩展性</li>
</ul>
</li>
<li>劣势<ul>
<li>训练数据很大时模型很大</li>
<li>需要大量内存</li>
<li>性能较慢</li>
</ul>
</li>
</ul>
<h3 id="支持向量机-Support-Vector-Machine"><a href="#支持向量机-Support-Vector-Machine" class="headerlink" title="支持向量机 Support Vector Machine"></a>支持向量机 Support Vector Machine</h3><ul>
<li>对于二类分类，该方法在向量空间中找出一个决策超平面(分类函数 f(x) = wx + b)，对属于两个类别的文档向量进行有效粉绿<ul>
<li>通常有很多可能的分割超平面</li>
<li>找到最好的一个超平面: 最大间隔准则<ul>
<li>使得属于不同类别的数据点间隔最大</li>
</ul>
</li>
<li>间隔区边缘上的向量称为支撑向量</li>
</ul>
</li>
<li>实际上要求解一个带约束的二次规划(quadratic programming, QP)问题</li>
<li>训练结果<ul>
<li>支撑向量</li>
</ul>
</li>
<li>分类<ul>
<li>计算新文档向量与支撑向量的距离</li>
</ul>
</li>
<li>常用工具<ul>
<li>SVMLight</li>
<li>LIBSVM</li>
</ul>
</li>
<li>优势<ul>
<li>只有支撑向量用来对新文档分类</li>
<li>模型小</li>
<li>一般不会过拟合</li>
</ul>
</li>
<li>劣势<ul>
<li>训练过程非常复杂: 优化问题</li>
</ul>
</li>
</ul>
<h3 id="分类结果评估"><a href="#分类结果评估" class="headerlink" title="分类结果评估"></a>分类结果评估</h3><ul>
<li>对每个分类都可以计算出 precision, recall, F-measure<ul>
<li>一般侧重正例的结果</li>
</ul>
</li>
<li>总体评价: 精度(Accuracy) = 正确分类的样本数量 / 总样本数量</li>
</ul>
<h3 id="如何应用于实际"><a href="#如何应用于实际" class="headerlink" title="如何应用于实际"></a>如何应用于实际</h3><ul>
<li>大多数应用都是直接采用已有的分类算法与工具<ul>
<li>不需要开发新的</li>
</ul>
</li>
<li>关键在于特征工程<ul>
<li>针对特定应用问题寻找合理、有效的特征集</li>
</ul>
</li>
<li>一般需要调节分类算法与工具的多个参数<ul>
<li>比如 KNN 中的 K，SVM 中的 C 参数等</li>
</ul>
</li>
</ul>
<h2 id="聚类"><a href="#聚类" class="headerlink" title="聚类"></a>聚类</h2><ul>
<li>给定一个数据点集合，每个数据点具有一组属性，数据点之间能进行相似度度量，聚类目标为找到若干类簇：<ul>
<li>同一类簇中的数据点相似</li>
<li>不同类簇中的数据点不相似</li>
</ul>
</li>
<li>无监督学习<ul>
<li>没有标注数据</li>
<li>类簇未知</li>
</ul>
</li>
<li>相似度度量准则<ul>
<li>欧氏距离(L2 norm)</li>
<li>余弦准则</li>
<li>L1 范式(L1 norm)</li>
</ul>
</li>
<li>聚类算法<ul>
<li>K-Means 聚类</li>
<li>层次式聚类(Hierarchical clustering)</li>
<li>增量式单遍聚类</li>
<li>基于图分割的聚类</li>
<li>基于密度峰值的聚类</li>
</ul>
</li>
</ul>
<p>应用：文档聚类</p>
<ul>
<li>目标：发现文档类簇，同一类簇中文档相似(基于重要词语)</li>
<li>方法：识别每篇文档中的重要词语，基于文档相似性进行聚类</li>
</ul>
<h3 id="层次式聚类"><a href="#层次式聚类" class="headerlink" title="层次式聚类"></a>层次式聚类</h3><ul>
<li>自底向上的凝聚式聚类(Agglomerative clustering)<ul>
<li>初始每个文档自成一个类簇</li>
<li>每次合并最相似/距离最近的两个类簇，形成一个新类簇，循环执行，直到满足终止条件<ul>
<li>终止条件为类簇数量或者相似度阈值</li>
</ul>
</li>
<li>结果为树形图</li>
</ul>
</li>
<li>不同的计算类簇间距离/相似性的方法<ul>
<li>最小距离(single link)</li>
<li>最大距离(complete link)</li>
<li>平均距离(group average)</li>
</ul>
</li>
<li>自顶向下的划分式聚类(Divisive clustering)<ul>
<li>初始只有一个类簇，包括所有文档</li>
<li>每次从当前类簇中选择最大(或最不合理)的一个类簇，将其分割成两个(或多个)新的类簇，循环执行，直到满足终止条件<ul>
<li>类簇分割方法可以采用其他聚类方法，比如 K 均值算法等</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="K-均值-K-means-聚类"><a href="#K-均值-K-means-聚类" class="headerlink" title="K 均值(K-means)聚类"></a>K 均值(K-means)聚类</h3><ul>
<li>一种基于划分的聚类算法</li>
<li>算法将文档集划分到 k 个类簇中<ul>
<li>每个类簇有一个类簇中心，称为 centroid</li>
<li>可基于该类簇文档向量的平均向量计算</li>
</ul>
</li>
<li>K 由用户指定</li>
</ul>
<h3 id="Buckshot-算法"><a href="#Buckshot-算法" class="headerlink" title="Buckshot 算法"></a>Buckshot 算法</h3><p>结合 K-means 与凝聚式聚类</p>
<ul>
<li>从原始 n 个数据点中随机取 √n 个数据点</li>
<li>针对这些样本数据点上运行凝聚式聚类</li>
<li>使用凝聚式聚类结果作为初始种子点</li>
<li>在元数据上基于初始种子点运行 K-means</li>
</ul>
<p>改善了种子点的选择</p>
<h3 id="增量式单遍聚类-Single-Pass"><a href="#增量式单遍聚类-Single-Pass" class="headerlink" title="增量式单遍聚类(Single-Pass)"></a>增量式单遍聚类(Single-Pass)</h3><ul>
<li>增量式聚类，适合于高效处理动态文本数据流</li>
<li>将新文档与已有类簇逐一对比，如果与某个类簇的相似度值大于设定的阈值，那么将该文档归并到相应类簇中，否则基于该文档形成一个新的类簇<ul>
<li>数据流中第一个文档形成第一个类簇</li>
</ul>
</li>
</ul>
<h3 id="基于图分割的聚类"><a href="#基于图分割的聚类" class="headerlink" title="基于图分割的聚类"></a>基于图分割的聚类</h3><ul>
<li>计算文档对之间的相似度值，构建相似度图 G=(V,E)<ul>
<li>每个文档为图的一个节点</li>
<li>文档之间有边连接，边的权重 W 为文档相似度</li>
</ul>
</li>
<li>文档聚类问题转换成在图上进行顶点分割的问题</li>
<li>切割标准 min cut(A,B)</li>
<li>问题<ul>
<li>只考虑了类簇之间的连接情况</li>
<li>没有考虑类簇内部的密度</li>
</ul>
</li>
<li>改进方法: Normalized Cut</li>
</ul>
<h3 id="基于密度峰值的聚类-Science"><a href="#基于密度峰值的聚类-Science" class="headerlink" title="基于密度峰值的聚类(Science)"></a>基于密度峰值的聚类(Science)</h3><ul>
<li>简单优美，可自动确定聚类数目，检测孤立点，可识别不同形状的聚类</li>
<li>假设: 类簇中心被一些局部密度较低的点围绕，并且这些点距离其他有高局部密度的点的距离都比较大</li>
<li>聚类过程<ul>
<li>计算出所有数据点的局部密度值和到高局部密度点的距离后，可以得到一张决策图</li>
<li>在决策图上挑选具有较大密度的样本点作为类簇中心</li>
<li>将其他样本点按照局部密度从高到底依次确定所属类簇，其类簇为领域内最近的高于该点局部密度的样本点所处的类簇</li>
</ul>
</li>
</ul>
<h3 id="半监督聚类"><a href="#半监督聚类" class="headerlink" title="半监督聚类"></a>半监督聚类</h3><p>除了带聚类的数据，还提供了少量先验知识</p>
<ul>
<li>部分标注信息<ul>
<li>例如为若干数据点标注了类簇</li>
</ul>
</li>
<li>约束信息<ul>
<li>例如要求某两个数据点必须在同一类簇，或者某两个数据点不能在同一类簇</li>
</ul>
</li>
<li>Seeded K-means<ul>
<li>用户提供了 Seeded points</li>
<li>利用提供的标注信息(seeded points)寻找初始类簇中心，然后运行 K-means</li>
<li>Seeded points 的标签可能会改变</li>
</ul>
</li>
<li>Constrained K-means<ul>
<li>用户提供了 Seeded points</li>
<li>利用提供的标注信息(seeded points)寻找初始类簇中心，然后运行 K-means</li>
<li>Seeded points 的标签不允许被改变</li>
</ul>
</li>
</ul>
<h3 id="聚类结果评估"><a href="#聚类结果评估" class="headerlink" title="聚类结果评估"></a>聚类结果评估</h3><ul>
<li>基于人工标注的类簇进行评价</li>
<li>评价准则包括: F 值、纯度(Purity)、规范化信息(NMI)</li>
</ul>
<h3 id="聚类算法的选择"><a href="#聚类算法的选择" class="headerlink" title="聚类算法的选择"></a>聚类算法的选择</h3><ul>
<li>聚类算法的选择具有挑战性<ul>
<li>每种算法都有各自的优势与不足，聚类效果通常依赖于聚类算法、距离函数、具体的数据与应用</li>
</ul>
</li>
<li>实际做法<ul>
<li>运行使用不同距离函数的多个聚类算法，分析和比较聚类结果</li>
</ul>
</li>
<li>对聚类结果的解释要基于原始数据的意义以及聚类算法的特性</li>
</ul>
<h3 id="半监督聚类-1"><a href="#半监督聚类-1" class="headerlink" title="半监督聚类"></a>半监督聚类</h3><ul>
<li>COP K-means<ul>
<li>用户提供了 must-link 与 cannot-link 约束</li>
<li>初始化: 类簇中心随机选择，但必须保证满足 must-link 约束，也就是 must-link 的两个数据点不能选择做为不同类簇的中心</li>
<li>算法: 一个数据点必须在不违反任何约束的情况下归属到临近的类簇</li>
</ul>
</li>
</ul>
<h3 id="检索结果聚类"><a href="#检索结果聚类" class="headerlink" title="检索结果聚类"></a>检索结果聚类</h3><ul>
<li>两类方法<ul>
<li>先对 snippet 进行聚类，然后为每个类簇选择标签</li>
<li>先分析获取有意义的类簇标签，然后将检索结果划分到不同标签</li>
</ul>
</li>
<li>基于后缀树的检索结果聚类(Suffix Tree Clustering, STC)<ul>
<li>时间复杂度低，高效</li>
<li>容易获得每个类簇的关键词标签</li>
<li>允许一个文档属于多个类簇</li>
</ul>
</li>
<li>基于回归学习的检索结果聚类<ul>
<li>现货的重要的短语代表类簇，然后再将检索结果跟类簇关联</li>
<li>同样允许一文档隶属多个类簇</li>
<li>候选短语(频率大于3的n-gram(n&lt;=3))</li>
<li>短语重要性排序<ul>
<li>看做回归问题</li>
<li>利用 SVM-Light 实现的支撑向量回归等多个回归方法</li>
<li>人工标注短语训练集，也即短语与其重要性分值</li>
</ul>
</li>
<li>短语特征<ul>
<li>Phrase Frequency/Inverted Document Frequency(TFIDF)</li>
<li>Phrase Length</li>
<li>Intra-Cluster Similarity</li>
<li>Cluster Entropy</li>
<li>Phrase Independence</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="智能问答基础技术"><a href="#智能问答基础技术" class="headerlink" title="智能问答基础技术"></a>智能问答基础技术</h2><p>起源于信息检索社区。根据用户的提问给出简短的答案，有时需要提供答案的证据。</p>
<h3 id="问题类型"><a href="#问题类型" class="headerlink" title="问题类型"></a>问题类型</h3><ul>
<li>根据答案类型划分<ul>
<li>事实型问题(Factual questions)</li>
<li>观点型问题(Opinions)</li>
<li>摘要型问题(Summaries)</li>
</ul>
</li>
<li>根据问题言语行为(question speech act)划分<ul>
<li>是否型问题(Yes/NO questions)</li>
<li>WH 问题(WH questions)</li>
<li>间接请求(Indirect Requests)</li>
<li>命令(Commands)</li>
</ul>
</li>
<li>复杂/困难问题<ul>
<li>为什么/怎么样(Why, How questions)</li>
<li>什么(What questions)</li>
</ul>
</li>
</ul>
<h3 id="主要技术"><a href="#主要技术" class="headerlink" title="主要技术"></a>主要技术</h3><ul>
<li>传统自动问答技术<ul>
<li>基于语料库的自动问答<ul>
<li>问题分析(分类、模板匹配、语义分析)</li>
<li>段落检测(段落抽取、排序)</li>
<li>答案抽取(实体识别、模板匹配、排序)</li>
</ul>
</li>
<li>基于知识库的自动问答</li>
</ul>
</li>
<li>社区问答技术<ul>
<li>问题分类、问题推荐</li>
<li>专家发现、信誉评估</li>
<li>知识抽取</li>
</ul>
</li>
</ul>
<h2 id="互联网信息抽取"><a href="#互联网信息抽取" class="headerlink" title="互联网信息抽取"></a>互联网信息抽取</h2><p><strong>非结构化数据</strong>(纯文本，句子，查询字符串) 和<strong>半结构化数据</strong>(HTML文档，查询日志，词典) -IE-&gt; <strong>结构化数据</strong>(语义知识)</p>
<ul>
<li>网页主要文本抽取(BTE)方法<ul>
<li>识别出一个包含最多词语(排除最多标签)的连续区域</li>
</ul>
</li>
<li>基于文本标签比例的抽取方法(CERT, Content Extraction via Tag Ratios)<ul>
<li>绘制文本标签直方图</li>
<li>对文本标签直方图进行变换，并进行聚类，得到网页内容</li>
</ul>
</li>
<li>基于网页分块重要性识别的抽取方法(Learning Block Importance Models for Web Pages)<ul>
<li>首先将网页分为块状区域(VIPS, 基于视觉的网页分块算法)</li>
<li>然后对每块区域判断重要性</li>
</ul>
</li>
<li>基于模板的方法<ul>
<li>基于批量处子统一模板的网页来自动检测模板</li>
<li>利用模板抽取网页内容</li>
</ul>
</li>
</ul>
<h3 id="文本语义信息抽取"><a href="#文本语义信息抽取" class="headerlink" title="文本语义信息抽取"></a>文本语义信息抽取</h3><p><strong>主要任务</strong></p>
<ul>
<li>命名实体抽取(Named entity extraction)<ul>
<li>命名实体识别(Named entity recognitoin, NER)</li>
<li>共指消解(Co-reference resolution)</li>
</ul>
</li>
<li>属性抽取(Attribute extraction)</li>
<li>关系挖掘(Relation mining)<ul>
<li>相关短语和实体(Related terms and entities)</li>
<li>归类(Categorization)</li>
<li>关系检测与分类(Relation detection and classification)</li>
</ul>
</li>
<li>事件挖掘(Event mining)<ul>
<li>事件检测与分类(Event detection and classification)</li>
</ul>
</li>
</ul>
<h3 id="实体识别"><a href="#实体识别" class="headerlink" title="实体识别"></a>实体识别</h3><ul>
<li>识别文本中出现的实体<ul>
<li>MUC(1997): Person, Location, Organization, Date/Time/Currency</li>
<li>ACE(2005): 100 多种更具体的类型</li>
</ul>
</li>
<li>人工规则 vs 机器学习方法</li>
<li>针对不同试题类型与领域考虑不同方法<ul>
<li>封闭类(e.g., geographical locations, disease names, gene &amp; protein names): 人工规则 + 词典</li>
<li>语法相关(e.g., phone numbers, zip codes): 正则表达式</li>
<li>语义相关(e.g., person and compnay names): 综合考虑上下文，句法特征，词典，启发式规则等</li>
<li>对于典型的实体类型抽取效果已经较好</li>
</ul>
</li>
</ul>
<h3 id="语义类挖掘"><a href="#语义类挖掘" class="headerlink" title="语义类挖掘"></a>语义类挖掘</h3><ul>
<li>目标：发现同位短语(coordinate terms), 类似于可比实体发现</li>
<li>主要方法<ul>
<li>一阶共现(First-order co-occurrences): 普通共现 &amp; 模板</li>
<li><strong>二阶共现(Second-order co-occurrences)</strong>: 分布式相似性<ul>
<li>分布式假设：出现在相似上下文(词语、句法)中的词语比较相似</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>基于分布相似性(DS)</strong></p>
<ul>
<li>定义上下文：句法上下文，词语上下文</li>
<li>将每个短语表示为一个特征向量<ul>
<li>特征：短语出现的一个上下文</li>
<li>特征值：上下文针对短语的权重</li>
</ul>
</li>
<li>计算短语相似性<ul>
<li>特征向量之间的相似性</li>
</ul>
</li>
</ul>
<p><strong>语义层级构建</strong></p>
<ul>
<li>主要子任务<ul>
<li>为短语(term)赋予类标签或上位词(label)<ul>
<li>Beijing -&gt; city, cpatial</li>
<li>Apple -&gt; company, fruit</li>
<li>Red -&gt; Color</li>
<li>方法: Pattern matching + counting<ul>
<li>人工设计或自动生成模板</li>
<li>文本模板或 HTML 表格</li>
<li>输出 <term, label,="" pattern,="" source,="" weight=""> 元组</term,></li>
</ul>
</li>
<li>挑战<ul>
<li>边界检测: 短语边界、标签边界</li>
<li>标签选择</li>
</ul>
</li>
<li>合并元组<ul>
<li>对于每个短语 T 与标签 L，计算 w(T, L)</li>
</ul>
</li>
<li>方法:简单计数<ul>
<li>对于每对(T, L)统计<t, l,="" p,="" s,="" w="">元组的数量</t,></li>
<li>或者 TF-IDF</li>
</ul>
</li>
</ul>
</li>
<li>为语义类(semantic class)赋予类标签(label)<ul>
<li>{Beijing, Shanghai, Dalian…} -&gt; cities, Chinese cities…</li>
<li>方法: 投票(Voting)</li>
</ul>
</li>
<li>构建层级</li>
</ul>
</li>
</ul>
<p><strong>通用关系</strong></p>
<p>关系: 与实体相关的事实</p>
<p>历史: MUC-7(1997) 提出，ACE、KBP 扩展</p>
<p><strong>关系抽取方法</strong></p>
<ul>
<li>基于知识/规则的方法<ul>
<li>专家制定规则、模板(可以基于词汇、句法结构)</li>
</ul>
</li>
<li>机器学习方法<ul>
<li>半监督学习：基于人工标注数据训练模型</li>
<li>半监督学习：基于自举方法从种子样例中训练模型<ul>
<li>自举方法(Bootstrapping): DIPRE(Brin 1998, 双重迭代模板关系抽取)</li>
</ul>
</li>
<li>混合或交互系统<ul>
<li>专家与机器学习算法交互(e.g., active learning)从而迭代优化/扩展规则和模板</li>
<li>交互包括标注样例、修改规则等</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>属性抽取(Attribute Extraction)</strong></p>
<ul>
<li>基于无结构化文本</li>
<li>基于 HTML 表格</li>
<li>基于 Wikipedia Infobox</li>
</ul>
<h3 id="相关系统"><a href="#相关系统" class="headerlink" title="相关系统"></a>相关系统</h3><ul>
<li>NeedleSeek<ul>
<li>needleseek.msra.cn</li>
<li>基于 Web 大规模数据挖掘开放域语义知识</li>
<li>基于挖掘的语义知识回答/服务用户需求</li>
<li>语义卡片(Semantic Card)<ul>
<li>将输入的词或段誉映射为一个或多个概念</li>
</ul>
</li>
<li>语义图(Semantic Map)<ul>
<li>概念组织成语义类，并获取概念之间的语义关系</li>
</ul>
</li>
</ul>
</li>
<li>人立方系统<ul>
<li>renlifang.msra.cn 中文</li>
<li>entitycube.research.microsoft.com 英文</li>
<li>侧重人物、机构之间的关系</li>
</ul>
</li>
<li>谷歌知识图谱<ul>
<li>实体关系网络</li>
</ul>
</li>
</ul>
<h2 id="情感分析与观点挖掘"><a href="#情感分析与观点挖掘" class="headerlink" title="情感分析与观点挖掘"></a>情感分析与观点挖掘</h2><ul>
<li>应用<ul>
<li>产品比较与推荐</li>
<li>个人与机构声誉分析</li>
<li>电视节目满意度分析</li>
<li>互联网舆情分析<ul>
<li>利用文本情感计算技术深入分析人们对社会现实和现象的群体性情绪、观点、思想、心理、意志和要求</li>
</ul>
</li>
<li>反恐与维稳</li>
</ul>
</li>
<li>原型系统与产品<ul>
<li>英文: OpinionFinder, RapidMiner, TextMap, Bing 产品搜索, condersr.com, tweetfeel.com</li>
<li>中文: 爱搜车众评, 雅虎人物搜索</li>
</ul>
</li>
</ul>
<h3 id="研究框架"><a href="#研究框架" class="headerlink" title="研究框架"></a>研究框架</h3><ul>
<li>应用层：情感检索，情感摘要，情感问答</li>
<li>核心层：情感要素抽取，情感倾向性分析，主客观分析/观点文本识别</li>
<li>基础层：NLP 基本模块，情感资源收集与标注</li>
<li>来源：产品评论，电影评论，新闻评论，博客，微博</li>
</ul>
<h3 id="情感分类"><a href="#情感分类" class="headerlink" title="情感分类"></a>情感分类</h3><ul>
<li>将文本按照所表达的总体情感进行分类<ul>
<li>例如正面(Positive), 负面(Negative), 中性(neutral)</li>
</ul>
</li>
<li>基于话题的文本分类相似又不同<ul>
<li>话题词汇很重要</li>
<li>情感词汇更重要，如: great, excellent, horrible, bad, worst, …</li>
</ul>
</li>
</ul>
<p><strong>情感分析任务</strong></p>
<ul>
<li>主客观分析/观点文本识别<ul>
<li>客观：反映关于世界的事实信息</li>
<li>主观：反映个人情感、信念等</li>
</ul>
</li>
<li>倾向性分析(可看作主客观分析的细粒度处理)<ul>
<li>对包含观点的文本进行倾向性判断</li>
<li>一般分为三类：褒义、贬义、中性(在一些问题不考虑中性)</li>
</ul>
</li>
<li>情绪分析<ul>
<li>愤怒、高兴、喜好、悲哀、吃惊等等</li>
</ul>
</li>
<li>粒度<ul>
<li>词、句子、文档</li>
</ul>
</li>
</ul>
<p><strong>情感资源</strong></p>
<ul>
<li>情感分析的基础</li>
<li>英文资源较多<ul>
<li>情感词典: WentiWordNet, Inquirer 等<ul>
<li>包含词语、短语等</li>
<li>倾向性词语、主观性词语</li>
</ul>
</li>
<li>已标注语料库数量较多</li>
<li>开源情感分析工具 OpinionFinder</li>
</ul>
</li>
<li>中文资源较少，但逐年增多<ul>
<li>知网 Hownet 提供了部分情感词汇</li>
<li>近两年的评测提供了中文标注文本<ul>
<li>NTCIR, COAE, NLP&amp;CC 等</li>
</ul>
</li>
</ul>
</li>
<li>情感资源基本上跟领域、语言有关</li>
<li>主客观分析与倾向性分析的资源也不一样</li>
</ul>
<h3 id="情感词汇资源构建"><a href="#情感词汇资源构建" class="headerlink" title="情感词汇资源构建"></a>情感词汇资源构建</h3><ul>
<li>基于心理学的评价理论</li>
<li>任务<ul>
<li>确定词语的主观性(subjectivity)</li>
<li>确定词语的倾向(orientation)</li>
<li>确定词语态度的强度(strength)</li>
</ul>
</li>
<li>连接词方法(Conjunction Method)<ul>
<li>用 and 相连的形容词通常具有相同的倾向，而用 but 的则具有相反的倾向</li>
<li>对形容词按照不同倾向聚类</li>
</ul>
</li>
<li>PMI 方法(Pointwise Mutual Information 点互信息, Orientation, Subjectivity)<ul>
<li>判别倾向性：具有相似倾向性的词语倾向于在文档中共同出现</li>
<li>判别主观性：主观性形容词倾向于出现在其他主观性形容词周围</li>
<li>可基于 AltaVista 搜索引擎的 NEAR 操作符返回的结果数进行 PMI 的计算</li>
<li>预测词语的倾向性 SO(t)</li>
</ul>
</li>
<li>WordNet 扩展方法<ul>
<li>著名的英文词义关系计算资源，词义数据库，包含词义及其关系</li>
<li>wordnet.princeton.edu</li>
<li>WordNet 中基本单元为Synset(synonym set): (近似)同义集合<ul>
<li>WordNet 的基本单元</li>
<li>每个 synset 表示一个语义概念</li>
<li>Example synset: {hit, strike, impinge on, run into, collide with}</li>
</ul>
</li>
<li>每个词条包括多个 synsets, 注释，使用样例等信息</li>
<li>Synsets 通过不同的词义关系相连</li>
<li>使用词语之间的同义、反义关系</li>
<li>假设：形容词通常与其同义词具有相同的倾向性，而与反义词具有相反的倾向性</li>
<li>利用种子形容词集，能够获得 WordNet 中所有形容词的倾向性</li>
</ul>
</li>
<li>释义方法(Gloss Use Method)<ul>
<li>Orientation, Subjectivity, SentiWordNet</li>
<li>假设<ul>
<li>倾向性：具有相似倾向性的词语具有相似的释义</li>
<li>主观性：具有相似倾向性的词语具有相似的释义，不具有倾向性的词语具有无倾向的释义</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="观点抽取"><a href="#观点抽取" class="headerlink" title="观点抽取"></a>观点抽取</h3><p>一个观点表示为一个五元组(目标对象, 目标对象特征, 观点的情感值, 观点持有者, 观点表达时间)</p>
<p>观点抽取任务很困难，<strong>重点关注两个子任务</strong></p>
<ul>
<li>特征抽取与聚类(aspect extraction and grouping)<ul>
<li>抽取对象的所有特征表达，并将同义特征表达聚类。每个特征类表示了关于该对象的独一无二的某个特征</li>
</ul>
</li>
<li>特征情感分类(aspect sentiment classification)<ul>
<li>确定观点针对每个特征的情感倾向：正面、负面、中性</li>
</ul>
</li>
</ul>
<p><strong>对象特征抽取</strong></p>
<ul>
<li>频繁特征：被许多评论提及的特征</li>
<li>非频繁特征抽取：基于同一情感词被用来描述不同特征与对象</li>
</ul>
<h2 id="信息摘要"><a href="#信息摘要" class="headerlink" title="信息摘要"></a>信息摘要</h2><p>对海量数据内容进行<strong>提炼与总结</strong>，以<strong>简洁、直观</strong>的摘要来概括用户所关注的主要内容，方便用户快速了解与浏览海量内容</p>
<h3 id="文档摘要基本技术"><a href="#文档摘要基本技术" class="headerlink" title="文档摘要基本技术"></a>文档摘要基本技术</h3><ul>
<li>早期论文: Luhn. The Automatic Creation of Literature Abstracts(1958)</li>
<li>研究 50 多年，有一定进展，但仍不能令人满意</li>
<li>代表系统<ul>
<li><strong>NewsInEssence</strong> by University of Michigan</li>
<li><strong>NewsBlaster</strong> by Columnbia University</li>
</ul>
</li>
<li>摘要任务多样化：单文档摘要，多文档摘要，查询相关的多文档摘要</li>
<li>摘要方法分类<ul>
<li><strong>抽取式</strong><ul>
<li>从文档中抽取已有句子形成摘要</li>
<li>实现简单，能保证句子的可读性</li>
</ul>
</li>
<li><strong>生成式/混合式</strong><ul>
<li>生成新的句子，或者对已有句子进行压缩、重构与融合</li>
<li>难度更大，但更接近摘要的本质</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="抽取式文档摘要"><a href="#抽取式文档摘要" class="headerlink" title="抽取式文档摘要"></a>抽取式文档摘要</h3><p><strong>典型框架</strong></p>
<p>文档集 -&gt; 文档理解 -&gt; <strong>句子重要性计算与排名(利用词语句子的各类特征，基于机器学习)</strong> -&gt; 句子选择 -&gt; 摘要句子排序 -&gt; 摘要</p>
<p><strong>关键问题</strong></p>
<p>如何衡量句子的重要性</p>
<ul>
<li>影响句子重要性的因素<ul>
<li>句子长度</li>
<li>句子位置</li>
<li>句子中词语的 TFIDF</li>
<li>句子是否包括线索词</li>
<li>句子是否与标题相似</li>
</ul>
</li>
</ul>
<p><strong>不同方法</strong></p>
<ul>
<li>基于单一因素的摘要方法<ul>
<li>只考虑句子位置</li>
<li>Lead Baseline<ul>
<li>抽取一篇文档中前几句话形成摘要</li>
</ul>
</li>
<li>Coverage Baseline<ul>
<li>轮流从不同文档中抽取第一、第二…第 K 句话形成摘要</li>
</ul>
</li>
</ul>
</li>
<li>基于启发式规则<ul>
<li>基于经验性公式综合考虑少数几个因素</li>
<li>例如: centroid-based method, 考虑了句子包含词语权重、句子位置、句子与首句相似度</li>
</ul>
</li>
<li>基于有监督学习的方法<ul>
<li>可考虑众多因素，由机器学习算法确定最优组合</li>
<li>句子分类<ul>
<li>二类分类：句子是否隶属于摘要</li>
<li>SVM</li>
</ul>
</li>
<li>序列标注<ul>
<li>为每个句子打上标签</li>
<li>可考虑相邻句子之间的关系</li>
<li>HMM, CRF</li>
</ul>
</li>
<li>句子回归<ul>
<li>为每个句子预测一个反应重要性的分数</li>
<li>SVR</li>
</ul>
</li>
</ul>
</li>
<li>基于图排序的方法<ul>
<li>如 LexRank, TextRank</li>
<li>只依赖于句子相似度</li>
<li>基于 PageRank 算法或相似算法</li>
<li>步骤<ul>
<li>构建图 G = (V, E)，句子作为定点，句子之间有关系则构成边</li>
<li>应用 PageRank 算法或相似算法获得每个顶点的权重</li>
<li>基于句子权重选择句子形成摘要</li>
</ul>
</li>
</ul>
</li>
<li>摘要冗余去除<ul>
<li>多文档摘要中不同文档中的句子可能有重复内容</li>
<li>摘要很短，应该尽可能包括多样化内容</li>
<li>选择与摘要中已有句子冗余度小的句子</li>
<li>MMR 方法</li>
</ul>
</li>
<li>基于整数线性规划(ILP)的方法<ul>
<li>将摘要看做一个带约束的优化问题</li>
<li>基于 ILP 进行求解，可采用现成的 ILP 求解工具<ul>
<li>比如 IBM CPLEX Optimizer</li>
</ul>
</li>
<li>同时进行句子抽取与冗余去除</li>
</ul>
</li>
<li>摘要句子排序<ul>
<li>句子顺序直接影响摘要可读性</li>
<li>单文档摘要中句子顺序容易确定<ul>
<li>依据句子在原文档中的顺序即可</li>
</ul>
</li>
<li>多文档摘要中句子顺序较难确定<ul>
<li>可综合考虑句子所在上下文信息进行排序</li>
<li>先确定任何两句之间的先后顺序</li>
<li>再确定多个句子之间的整体顺序</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>目前摘要总体性能不高，需要方法上的突破。</p>
<h3 id="相关评测"><a href="#相关评测" class="headerlink" title="相关评测"></a>相关评测</h3><ul>
<li>DUC<ul>
<li>NIST 组织, 2000-2007</li>
<li>主要任务(传统)：单文档、多文档、查询相关摘要</li>
</ul>
</li>
<li>TAC Summarization Track<ul>
<li>NIST 组织, 2008-2011, 2014</li>
<li>主要任务(新型)<ul>
<li>Update Summarization</li>
<li>Opinion Summarization</li>
<li>Guided Summarization</li>
<li>AESOP(摘要自动评价)</li>
<li>Biomedical Summarization</li>
</ul>
</li>
</ul>
</li>
<li>NTCIR-9~10: 1click(新型)</li>
<li>TREC2013: Temporal Summarization Track(新型)</li>
</ul>
<h2 id="社交网络分析"><a href="#社交网络分析" class="headerlink" title="社交网络分析"></a>社交网络分析</h2><ul>
<li>社会媒体的特性<ul>
<li>用户生成内容多，富含观点</li>
<li>群体智慧</li>
<li>用户交互性强</li>
<li>异构网络</li>
</ul>
</li>
<li>社交媒体分析<ul>
<li>社交网络分析<ul>
<li>基于社交关系、结构进行挖掘</li>
<li>例如：社区检测、连接预测、影响力分析</li>
</ul>
</li>
<li>社交内容挖掘<ul>
<li>基于文本等内容数据进行挖掘</li>
<li>例如：摘要、关键词、情感分析</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>社交网络可以用矩阵表示</p>
<h3 id="社会网络"><a href="#社会网络" class="headerlink" title="社会网络"></a>社会网络</h3><ul>
<li>由相互关联的节点(个体或机构)组成的结构<ul>
<li>不同关系：例如好友关系、亲属关系等</li>
</ul>
</li>
<li>图表示<ul>
<li>节点 = 成员</li>
<li>边 = 关系</li>
</ul>
</li>
<li>现实例子<ul>
<li>好友网络(facebook, renren, wechat)</li>
<li>媒体分享(Flickr, Youtube)</li>
<li>社会标注(Del.icio.us)</li>
</ul>
</li>
<li>相关任务<ul>
<li>社交网络抽取(Social Network Extraction)<ul>
<li>从数据源中抽取、构建社交网络</li>
</ul>
</li>
<li><strong>网络中心性分析(Network Centrality Analysis)</strong><ul>
<li>识别社交网络上最重要的节点(重要性的定义由目的、环境所定)</li>
<li>输入：一个社交网络</li>
<li>输出：最重要的节点列表</li>
<li>方法：为节点计算分数或排序，反映节点的重要性/专业性/影响力</li>
<li>课采用链接分析领域的不同算法<ul>
<li>PageRank 算法及其变种</li>
<li>HITS 算法确定权威源</li>
</ul>
</li>
<li>可以采用<strong>网络中心性测度(Centrality measures)</strong>来评估节点重要性</li>
<li>代表性测度<ul>
<li>度数中心性 Degree Centrality -&gt; 入度中心性(indegree centrality, 有向图上的拓展)<ul>
<li>有最多朋友的人最重要</li>
</ul>
</li>
<li>中介中心性 Betweenness Centrality<ul>
<li>有多少对节点为了以最短路径到达彼此必须经过给定节点？</li>
</ul>
</li>
<li>亲近中心性 Closeness Centrality<ul>
<li>一个节点的亲近中心性基于该节点与图中所有节点的平均最短路径计算得到</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><strong>社区检测(Community Detection)</strong><ul>
<li>一个社区由一个节点结合所表示，该集合中节点之间交互频繁</li>
<li>多种方法<ul>
<li>基于子图可达性(K-clique, K-club)</li>
<li>基于节点聚类<ul>
<li>节点相似性基于它们的交互模式的相似性而定义</li>
<li>两个节点结构相似(structurally equivalent)，如果它们连接到相同的其他节点</li>
<li>实际上使用向量相似性(cosine similary, Jaccard similarity, …)</li>
<li>应用 K-means Clustering Algorithm</li>
</ul>
</li>
<li>基于图分割<ul>
<li>不同社区之间的交互应该不频繁</li>
<li>图分割 Cut: 两个节点集之间的边的数量</li>
<li>目标: 最小化 Cut<ul>
<li>不足：经常获得包含一个节点的社区</li>
<li>需要考虑社区大小</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>分类(Classification)<ul>
<li>用户的行为倾向可表达为类别标签<ul>
<li>是否点击了一个广告</li>
<li>是否对特定的话题感兴趣</li>
<li>喜欢/不喜欢一个产品</li>
</ul>
</li>
<li>输入<ul>
<li>一个社交网络</li>
<li>部分节点的类别标签</li>
</ul>
</li>
<li>输出<ul>
<li>网络中其他节点的类别标签</li>
</ul>
</li>
</ul>
</li>
<li>链接预测(Link Prediction)<ul>
<li>给定一个社交网络，预测哪些节点相互连接</li>
<li>输出一个节点对列表</li>
<li>例如: facebook 中的好友推荐</li>
</ul>
</li>
<li>病毒式营销(Viral Marketing)<ul>
<li>找出若干用户，为其提供优惠或折扣，从而影响网络上的其他用户，使得收益最大化</li>
<li>找到能够覆盖网络的最小节点集合(可用贪心选择)</li>
</ul>
</li>
<li>网络建模(Network Modeling)<ul>
<li>发现网络的统计模式<ul>
<li>Small-world effect(e.g., 6 degrees of separation)</li>
<li>Power-law distribution(a.k.a. scale-free distribution)</li>
<li>Community structure(high clustering coefficient)</li>
</ul>
</li>
<li>对网络动力学进行建模</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="异构网络"><a href="#异构网络" class="headerlink" title="异构网络"></a>异构网络</h3><ul>
<li>网络中具有不同类型/模态的节点对象<ul>
<li>YouTube: Users, tags, videos, ads</li>
<li>Del.icio.us: Users, tags, bookmarks</li>
</ul>
</li>
<li>网络中节点之间具有不同类型/维度的交互<ul>
<li>Facebook: Send email, leave a message, write a comment, tag photos</li>
<li>Same users interacting at different sites: Facebook, YouTube, Twitter</li>
</ul>
</li>
<li>多模网络 Multi-Mode Network<ul>
<li>网络中包含多模态对象</li>
</ul>
</li>
<li>多维网络 Multi-Dimensional Network<ul>
<li>网络中包含节点间的异构链接</li>
</ul>
</li>
</ul>
<p>异构网络在现实中非常普遍，对异构网络的分析与挖掘更具挑战性，是当前数据挖掘领域研究的热点</p>
<h2 id="信息推荐"><a href="#信息推荐" class="headerlink" title="信息推荐"></a>信息推荐</h2><h3 id="推荐技术"><a href="#推荐技术" class="headerlink" title="推荐技术"></a>推荐技术</h3><ul>
<li>基于内容的过滤/推荐(Content-based Filtering/Recommendation)<ul>
<li>基于用户的历史推荐物品</li>
<li>基于内容特征描述来预测用户的偏好</li>
</ul>
</li>
<li>协同过滤/推荐(Collaborative Filtering/Recommendation)<ul>
<li>基于用户群体行为</li>
<li>基于其他具有相似行为的用户为给定用户推荐物品</li>
</ul>
</li>
<li>混合式</li>
</ul>
<h3 id="基于内容的推荐"><a href="#基于内容的推荐" class="headerlink" title="基于内容的推荐"></a>基于内容的推荐</h3><ul>
<li>主要思想：为一个用户推荐与该用户之前感兴趣的物品相似的物品<ul>
<li>电影推荐：推荐具有相同演员、导演、类型的电影</li>
<li>新闻推荐：推荐具有相似话题的新闻</li>
</ul>
</li>
<li>用户配置档案(User Profiling)是关键<ul>
<li>用户画像</li>
<li>基于用户的历史推荐物品</li>
<li>从样例内容特征描述中基于机器学习与数据挖掘算法获得关于用户兴趣爱好的配置档案</li>
</ul>
</li>
<li>物品表示(Item Representation)<ul>
<li>物品一般存储在数据库表中</li>
<li>结构化数据<ul>
<li>一定数量的属性</li>
<li>每个物品由同样的属性集所描述</li>
<li>属性的取值范围一般明确</li>
</ul>
</li>
<li>非结构化数据<ul>
<li>自由文本，可转为结构化表达</li>
<li>每个词可看做一个属性</li>
</ul>
</li>
</ul>
</li>
<li>用户配置档案(User Profile)<ul>
<li>包含两类信息<ul>
<li>用户兴趣模型，例如，一个能预测用户对某个物品感兴趣可能性的函数表达(可以机器学习建模)</li>
<li>用户交互历史，例如，用户浏览的物品，用户购买的物品等</li>
</ul>
</li>
<li>用户交互历史可用作训练数据，基于该训练数据采用机器学习算法创建用户兴趣模型</li>
<li>可由用户人工创建<ul>
<li>提供选项界面供用户构建</li>
<li>简单数据库查询课找到满足用户条件的物品并推荐给用户</li>
<li>不足<ul>
<li>耗费用户精力</li>
<li>不能及时反映兴趣爱好的变化</li>
<li>不能对推荐物品进行排序</li>
</ul>
</li>
</ul>
</li>
<li>基于机器学习的用户建模<ul>
<li>基于分类学习从用户历史中对用户兴趣建模<ul>
<li>应用分类函数能够获得用户对某物品感兴趣的概率</li>
</ul>
</li>
<li>多种分类学习算法可以应用<ul>
<li>决策树：构建一颗决策树表示用户兴趣爱好</li>
<li>最近邻：将所有训练样例存储于内存中，为新的物品找到 K 个最近邻的物品，从用户对这些最近邻物品的偏好计算用户对新物品的偏好</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="协同推荐"><a href="#协同推荐" class="headerlink" title="协同推荐"></a>协同推荐</h3><ul>
<li>基于用户群体</li>
<li>方法<ul>
<li>对于给定的用户，找到相似的用户</li>
<li>为给定用户推荐被相似用户高度评分的物品(未被给定用户评分)</li>
</ul>
</li>
<li>优势<ul>
<li>不需要分析内容</li>
<li>能够捕捉微妙的线索、关系</li>
</ul>
</li>
<li>三类主要的协同推荐<ul>
<li>基于用户<ul>
<li>思想：在过去对物品购买、评分一致的用户很可能再次一致</li>
<li>使用相似用户的意见预测特定用户对于一个物品的意见</li>
<li>用户相似性通过用户对其他物品的意见吻合程度来衡量<ul>
<li>算法1：使用整个矩阵</li>
<li>算法2：K 近邻</li>
</ul>
</li>
<li>用户冷启动(cold-start)问题<ul>
<li>不足以确定新用户的相似用户</li>
</ul>
</li>
<li>数据稀疏(sparsity)问题<ul>
<li>当物品数量很多时，用户通常只评价了极少一部分物品，同样难以找到相似用户</li>
</ul>
</li>
<li>扩展性问题<ul>
<li>当有百万用户和物品时，计算很慢</li>
</ul>
</li>
<li>物品冷启动问题<ul>
<li>不能为新物品预测用户评分，除非已有相似用户对该物品进行评分(注：基于内容的推荐中不存在该问题)</li>
</ul>
</li>
</ul>
</li>
<li>基于物品<ul>
<li>一个用户很可能对相似的物品具有相同的评分(类似基于内容的推荐)</li>
<li>物品相似性通过其他用户对物品的评分意见吻合程度来衡量(与基于内容的推荐不同)</li>
<li>相比于基于用户协同推荐的优势<ul>
<li>更好地处理用户冷启动问题</li>
<li>提高稳定性(物品相似性要比用户相似性更稳定)</li>
</ul>
</li>
</ul>
</li>
<li>基于矩阵分解<ul>
<li>将评分矩阵分解为两个矩阵(也可以是多个)，基于分解结果课计算获得用户对物品的评分(该评分在原始矩阵中不存在)</li>
<li>求解方法<ul>
<li>Alternating least squares</li>
<li>Stochastic gradient descent</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>需要一个评分矩阵<ul>
<li>矩阵每个元素表示一个用户针对一个物品的评分</li>
</ul>
</li>
<li>显式评分：用户评分，是否购买等</li>
<li>隐式评分：用户点击，页面浏览，浏览时间等</li>
</ul>
<h3 id="推荐结果的评估准则"><a href="#推荐结果的评估准则" class="headerlink" title="推荐结果的评估准则"></a>推荐结果的评估准则</h3><ul>
<li>根据不同的推荐问题和具体需求而选择<ul>
<li>Precision, Recall, MRR, Mean absolute error</li>
</ul>
</li>
</ul>
<h3 id="更多推荐技术"><a href="#更多推荐技术" class="headerlink" title="更多推荐技术"></a>更多推荐技术</h3><ul>
<li>基于社交网络的推荐</li>
<li>基于地理位置的推荐</li>
<li>多模态内容综合推荐</li>
<li>集合推荐/组合推荐</li>
</ul>
<h3 id="主要的开源工具"><a href="#主要的开源工具" class="headerlink" title="主要的开源工具"></a>主要的开源工具</h3><table>
<thead>
<tr>
<th style="text-align:left">Name</th>
<th style="text-align:right">Language</th>
<th style="text-align:right">Type</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">CofiRank</td>
<td style="text-align:right">C++</td>
<td style="text-align:right">collaborative filtering</td>
</tr>
<tr>
<td style="text-align:left">Crab</td>
<td style="text-align:right">Python</td>
<td style="text-align:right">recommendation</td>
</tr>
<tr>
<td style="text-align:left">EasyRec</td>
<td style="text-align:right">Java</td>
<td style="text-align:right">recommendation</td>
</tr>
<tr>
<td style="text-align:left">GraphLab</td>
<td style="text-align:right">C++</td>
<td style="text-align:right">high performance computation</td>
</tr>
<tr>
<td style="text-align:left">Lenskit</td>
<td style="text-align:right">Java</td>
<td style="text-align:right">recommendation</td>
</tr>
<tr>
<td style="text-align:left">Mahout</td>
<td style="text-align:right">Java</td>
<td style="text-align:right">general ML</td>
</tr>
<tr>
<td style="text-align:left">Python-recsys</td>
<td style="text-align:right">Python</td>
<td style="text-align:right">recommendation</td>
</tr>
<tr>
<td style="text-align:left">RapidMiner</td>
<td style="text-align:right">Java</td>
<td style="text-align:right">ML, NLP &amp; data mining</td>
</tr>
<tr>
<td style="text-align:left">SVDFeature</td>
<td style="text-align:right">C++</td>
<td style="text-align:right">matrix factorization</td>
</tr>
<tr>
<td style="text-align:left">Waffles</td>
<td style="text-align:right">C++</td>
<td style="text-align:right">ML and data mining</td>
</tr>
</tbody>
</table>

    
  </div>


          </div>
          

  <p>热评文章</p>
  <div class="ds-top-threads" data-range="weekly" data-num-items="4"></div>


          
  <div class="comments" id="comments">
    
      <div class="ds-thread" data-thread-key="vault/data-analysis-guide.html"
           data-title="数据分析指南" data-url="http://wdxtub.com/vault/data-analysis-guide.html">
      </div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel  sidebar-panel-active ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/misc/avatar.jpg"
               alt="wdxtub" />
          <p class="site-author-name" itemprop="name">wdxtub</p>
          <p class="site-description motion-element" itemprop="description">人文/科学/读书/写作/思考/编程/架构/数据/广交朋友/@SYSU/@CMU</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">710</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              
                <span class="site-state-item-count">10</span>
                <span class="site-state-item-name">分类</span>
              
            </div>
          

          
            <div class="site-state-item site-state-tags">
              
                <span class="site-state-item-count">874</span>
                <span class="site-state-item-name">标签</span>
              
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/wdxtub" target="_blank" title="GitHub">
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://weibo.com/wdxtub" target="_blank" title="微博">
                  
                  微博
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://douban.com/people/wdx" target="_blank" title="豆瓣">
                  
                  豆瓣
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://www.zhihu.com/people/wdxtub" target="_blank" title="知乎">
                  
                  知乎
                </a>
              </span>
            
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-inline">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              不妨看看
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="http://zhchbin.github.io/" title="zhchbin" target="_blank">zhchbin</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://www.algorithmdog.com/" title="算法狗" target="_blank">算法狗</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://www.52cs.org/" title="我爱计算机" target="_blank">我爱计算机</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://jackqdyulei.github.io/" title="雷雷" target="_blank">雷雷</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://guojiex.github.io/" title="瓜瓜" target="_blank">瓜瓜</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://wdxtub.lofter.com/" title="我的 Lofter" target="_blank">我的 Lofter</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://wdxtub.com/interview/" title="刷题笔记" target="_blank">刷题笔记</a>
                </li>
              
            </ul>
          </div>
        

      </section>

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy;  2013 - 
  <span itemprop="copyrightYear">2016</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">wdxtub</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="http://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>

        

<div class="busuanzi-count">

  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv"><i class="fa fa-user"></i><span class="busuanzi-value" id="busuanzi_value_site_uv"></span></span>
  

  
    <span class="site-pv"><i class="fa fa-eye"></i><span class="busuanzi-value" id="busuanzi_value_site_pv"></span></span>
  
  
</div>



        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.1"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.1"></script>



  

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"wdxblog"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.id = 'duoshuo-script';
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementById('footer')
      || document.getElementById('footer')).appendChild(ds);
    })();
  </script>

  
    
      
      <script src="/vendors/ua-parser-js/dist/ua-parser.min.js?v=0.7.9"></script>
      <script src="/js/src/hook-duoshuo.js"></script>
    
  





  
  
  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length == 0) {
       search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    function proceedsearch() {
      $("body").append('<div class="popoverlay">').css('overflow', 'hidden');
      $('.popup').toggle();

    }
    // search function;
    var searchFunc = function(path, search_id, content_id) {
    'use strict';
    $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
            // get the contents from search data
            isfetched = true;
            $('.popup').detach().appendTo('.header-inner');
            var datas = $( "entry", xmlResponse ).map(function() {
                return {
                    title: $( "title", this ).text(),
                    content: $("content",this).text(),
                    url: $( "url" , this).text()
                };
            }).get();
            var $input = document.getElementById(search_id);
            var $resultContent = document.getElementById(content_id);
            $input.addEventListener('input', function(){
                var matchcounts = 0;
                var str='<ul class=\"search-result-list\">';                
                var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                $resultContent.innerHTML = "";
                if (this.value.trim().length > 1) {
                // perform local searching
                datas.forEach(function(data) {
                    var isMatch = true;
                    var content_index = [];
                    var data_title = data.title.trim().toLowerCase();
                    var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                    var data_url = data.url;
                    var index_title = -1;
                    var index_content = -1;
                    var first_occur = -1;
                    // only match artiles with not empty titles and contents
                    if(data_title != '' && data_content != '') {
                        keywords.forEach(function(keyword, i) {
                            index_title = data_title.indexOf(keyword);
                            index_content = data_content.indexOf(keyword);
                            if( index_title < 0 && index_content < 0 ){
                                isMatch = false;
                            } else {
                                if (index_content < 0) {
                                    index_content = 0;
                                }
                                if (i == 0) {
                                    first_occur = index_content;
                                }
                            }
                        });
                    }
                    // show search results
                    if (isMatch) {
                        matchcounts += 1;
                        str += "<li><a href='"+ data_url +"' class='search-result-title'>"+ data_title +"</a>";
                        var content = data.content.trim().replace(/<[^>]+>/g,"");
                        if (first_occur >= 0) {
                            // cut out 100 characters
                            var start = first_occur - 20;
                            var end = first_occur + 80;
                            if(start < 0){
                                start = 0;
                            }
                            if(start == 0){
                                end = 50;
                            }
                            if(end > content.length){
                                end = content.length;
                            }
                            var match_content = content.substring(start, end);
                            // highlight all keywords
                            keywords.forEach(function(keyword){
                                var regS = new RegExp(keyword, "gi");
                                match_content = match_content.replace(regS, "<b class=\"search-keyword\">"+keyword+"</b>");
                            });
                            
                            str += "<p class=\"search-result\">" + match_content +"...</p>"
                        }
                        str += "</li>";
                    }
                })};
                str += "</ul>";
                if (matchcounts == 0) { str = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>' }
                if (keywords == "") { str = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>' }
                $resultContent.innerHTML = str;
            });
            proceedsearch();
        }
    });}

    // handle and trigger popup window;
    $('.popup-trigger').mousedown(function(e) {
      e.stopPropagation();
      if (isfetched == false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };

    });

    $('.popup-btn-close').click(function(e){
      $('.popup').hide();
      $(".popoverlay").remove();
      $('body').css('overflow', '');
    });
    $('.popup').click(function(e){
      e.stopPropagation();
    });
  </script>

  
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
  </script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for (i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
    });
  </script>
  <script type="text/javascript" src=""></script>


  

  
<script type="text/javascript" async src="//push.zhanzhang.baidu.com/push.js">
</script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->


</body>
</html>
